data:
  train_path: "../data/train.csv"
  test_path: "../data/test.csv"
  max_seq_length: 1024
  test_size: 0.1
  prompt:
    no_question: "지문:\n {paragraph}\n\n 질문:\n {question}\n\n 선택지:\n {choices}\n\n 1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.\n 정답:"
    with_question: "지문:\n {paragraph}\n\n 질문:\n {question}\n\n <보기>:\n {question_plus}\n\n 선택지:\n {choices}\n\n 1, 2, 3, 4, 5 중에 하나를 정답으로 고르세요.\n 정답:"

model:
  base_model: "beomi/gemma-ko-2b"
  model:
    torch_dtype: "float16"
    low_cpu_mem_usage: true
    use_cache: true # gradient_checkpointing이 true면 false여야함
    quantization: "" # BitsAndBytes
    bits: 8 # 8, 4, 2
    use_double_quant: false
  tokenizer:
    padding_side: "right"
    chat_template: "{% if messages[0]['role'] == 'system' %}{% set system_message = messages[0]['content'] %}{% endif %}{% if system_message is defined %}{{ system_message }}{% endif %}{% for message in messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<start_of_turn>user\n' + content + '<end_of_turn>\n<start_of_turn>model\n' }}{% elif message['role'] == 'assistant' %}{{ content + '<end_of_turn>\n' }}{% endif %}{% endfor %}"

training:
  response_template: "<start_of_turn>model"
  lora:
    r: 6
    lora_alpha: 8
    lora_dropout: 0.05
    target_modules: ["q_proj", "k_proj"]
    bias: "none"
    task_type: "CAUSAL_LM"

  params:
    do_train: true
    do_eval: true
    lr_scheduler_type: "cosine"
    max_seq_length: 1024
    per_device_train_batch_size: 1
    per_device_eval_batch_size: 1
    gradient_accumulation_steps: 1
    gradient_checkpointing: false
    max_grad_norm: 0.3
    num_train_epochs: 3
    learning_rate: 2.0e-05
    weight_decay: 0.01
    logging_strategy: "epoch"
    save_strategy: "epoch"
    eval_strategy: "epoch"
    save_total_limit: 2
    save_only_model: true
    report_to: "wandb"
    run_name: "../outputs" # wandb 세팅이 존재한다면 동적으로 생성됩니다.
    output_dir: "../outputs"
    overwrite_output_dir: true


inference:
  do_test: true
  output_path: "../outputs/"

log:
  file: "../log/file.log"
  level: "INFO"

wandb:
  project: generation_for_nlp
  entity: hidong1015-nlp04

exp:
  # 실험자 [sujin, seongmin, sungjae, gayeon, yeseo, minseo]
  username: fubao
